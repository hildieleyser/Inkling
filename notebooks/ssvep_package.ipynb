{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd07979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanya/.pyenv/versions/3.10.6/envs/inkling/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.6) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6907b03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Wearable SSVEP Dataset/S001.mat for subject S001\n",
      "Loaded data shape: (8, 710, 2, 10, 12)\n"
     ]
    }
   ],
   "source": [
    "# Configure which .mat object to load (defaults to S001)\n",
    "mat_object = os.getenv('GCS_OBJECT_MAIN', 'Wearable SSVEP Dataset/S001.mat')\n",
    "subject_id = os.path.splitext(os.path.basename(mat_object))[0]\n",
    "\n",
    "client = storage.Client.from_service_account_json(\n",
    "    os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    ")\n",
    "bucket = client.bucket(os.getenv('GCP_BUCKET_NAME'))\n",
    "\n",
    "print(f'Loading {mat_object} for subject {subject_id}')\n",
    "blob = bucket.blob(mat_object)\n",
    "data_bytes = blob.download_as_bytes()\n",
    "mat = sio.loadmat(io.BytesIO(data_bytes))\n",
    "\n",
    "data = mat['data']  # expected shape (channels, time, electrode, block, target)\n",
    "print('Loaded data shape:', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "422ed786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (240, 5)\n",
      "  subject electrode  block  target  \\\n",
      "0    S001       wet      1       1   \n",
      "1    S001       wet      1       2   \n",
      "2    S001       wet      1       3   \n",
      "3    S001       wet      1       4   \n",
      "4    S001       wet      1       5   \n",
      "\n",
      "                                              signal  \n",
      "0  [[-52325.52005800724, -53157.22841961553, -554...  \n",
      "1  [[-56806.91044371786, -58819.819022406286, -60...  \n",
      "2  [[-58424.81901793594, -57290.15513003797, -551...  \n",
      "3  [[-59719.47668310861, -61462.01857698074, -609...  \n",
      "4  [[-57667.36314698238, -60079.16093344456, -608...  \n",
      "Electrode counts:\n",
      "electrode\n",
      "wet    120\n",
      "dry    120\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Build epoch-level dataframe for a single subject (one row per electrode x block x target)\n",
    "expected_shape = (8, 710, 2, 10, 12)\n",
    "if data.shape != expected_shape:\n",
    "    raise ValueError(f'Unexpected data shape {data.shape}, expected {expected_shape}')\n",
    "\n",
    "rows = []\n",
    "electrode_map = {0: 'wet', 1: 'dry'}\n",
    "\n",
    "for e_idx in range(data.shape[2]):\n",
    "    for b_idx in range(data.shape[3]):\n",
    "        for t_idx in range(data.shape[4]):\n",
    "            rows.append(\n",
    "                {\n",
    "                    'subject': subject_id,\n",
    "                    'electrode': electrode_map.get(e_idx, str(e_idx)),\n",
    "                    'block': b_idx + 1,   # 1-based\n",
    "                    'target': t_idx + 1,  # 1-based\n",
    "                    'signal': data[:, :, e_idx, b_idx, t_idx],  # shape (8, 710)\n",
    "                }\n",
    "            )\n",
    "\n",
    "all_epochs = pd.DataFrame(rows)\n",
    "print('DataFrame shape:', all_epochs.shape)\n",
    "print(all_epochs.head())\n",
    "print('Electrode counts:')\n",
    "print(all_epochs['electrode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73aeae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102 subject .mat files\n",
      "full_df shape: (24480, 5)\n",
      "  subject electrode  block  target  \\\n",
      "0    S001       wet      1       1   \n",
      "1    S001       wet      1       2   \n",
      "2    S001       wet      1       3   \n",
      "3    S001       wet      1       4   \n",
      "4    S001       wet      1       5   \n",
      "\n",
      "                                              signal  \n",
      "0  [[-52325.52005800724, -53157.22841961553, -554...  \n",
      "1  [[-56806.91044371786, -58819.819022406286, -60...  \n",
      "2  [[-58424.81901793594, -57290.15513003797, -551...  \n",
      "3  [[-59719.47668310861, -61462.01857698074, -609...  \n",
      "4  [[-57667.36314698238, -60079.16093344456, -608...  \n",
      "Subject counts:\n",
      "subject\n",
      "S001    240\n",
      "S065    240\n",
      "S075    240\n",
      "S074    240\n",
      "S073    240\n",
      "       ... \n",
      "S032    240\n",
      "S031    240\n",
      "S030    240\n",
      "S029    240\n",
      "S102    240\n",
      "Name: count, Length: 102, dtype: int64\n",
      "Electrode counts:\n",
      "electrode\n",
      "wet    12240\n",
      "dry    12240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Build full multi-subject epoch DataFrame (102 subjects x 240 epochs)\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def load_mat_from_gcs(filepath):\n",
    "    \"\"\"Download a .mat from GCS and return the 'data' array.\"\"\"\n",
    "    client = storage.Client.from_service_account_json(\n",
    "        os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    "    )\n",
    "    bucket = client.bucket(os.getenv('GCP_BUCKET_NAME'))\n",
    "    blob = bucket.blob(filepath)\n",
    "    bytes_data = blob.download_as_bytes()\n",
    "    mat = sio.loadmat(io.BytesIO(bytes_data))\n",
    "    if 'data' not in mat:\n",
    "        raise KeyError(f\"'data' variable missing in {filepath}\")\n",
    "    arr = mat['data']\n",
    "    if arr.shape != (8, 710, 2, 10, 12):\n",
    "        raise ValueError(f\"Unexpected shape {arr.shape} in {filepath}\")\n",
    "    return arr\n",
    "\n",
    "\n",
    "def build_subject_df(subject_id, data):\n",
    "    \"\"\"Convert one subject's 5-D array into a 240-row DataFrame.\"\"\"\n",
    "    expected = (8, 710, 2, 10, 12)\n",
    "    if data.shape != expected:\n",
    "        raise ValueError(f\"Unexpected shape {data.shape}, expected {expected}\")\n",
    "\n",
    "    rows = []\n",
    "    for e_idx in range(2):\n",
    "        for b_idx in range(10):\n",
    "            for t_idx in range(12):\n",
    "                rows.append(\n",
    "                    {\n",
    "                        'subject': subject_id,\n",
    "                        'electrode': 'wet' if e_idx == 0 else 'dry',\n",
    "                        'block': b_idx + 1,\n",
    "                        'target': t_idx + 1,\n",
    "                        'signal': data[:, :, e_idx, b_idx, t_idx],\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# List all subject .mat files (skip non-subject files like Impedance.mat)\n",
    "client = storage.Client.from_service_account_json(\n",
    "    os.getenv('GOOGLE_APPLICATION_CREDENTIALS')\n",
    ")\n",
    "bucket = client.bucket(os.getenv('GCP_BUCKET_NAME'))\n",
    "prefix = 'Wearable SSVEP Dataset/'\n",
    "mat_files = []\n",
    "for b in bucket.list_blobs(prefix=prefix):\n",
    "    name = b.name\n",
    "    base = os.path.basename(name)\n",
    "    if not base.endswith('.mat'):\n",
    "        continue\n",
    "    if not re.match(r'S\\d+\\.mat$', base):\n",
    "        continue  # skip non-subject files (e.g., Impedance.mat)\n",
    "    mat_files.append(name)\n",
    "mat_files.sort()\n",
    "print(f'Found {len(mat_files)} subject .mat files')\n",
    "\n",
    "# Build combined DataFrame\n",
    "all_subject_dfs = []\n",
    "for fp in mat_files:\n",
    "    subject_id = os.path.splitext(os.path.basename(fp))[0]\n",
    "    try:\n",
    "        data_arr = load_mat_from_gcs(fp)\n",
    "    except (KeyError, ValueError) as exc:\n",
    "        print(f'Skipping {fp}: {exc}')\n",
    "        continue\n",
    "    df_subj = build_subject_df(subject_id, data_arr)\n",
    "    all_subject_dfs.append(df_subj)\n",
    "\n",
    "full_df = pd.concat(all_subject_dfs, ignore_index=True)\n",
    "\n",
    "# Summaries\n",
    "print('full_df shape:', full_df.shape)\n",
    "print(full_df.head())\n",
    "print('Subject counts:')\n",
    "print(full_df['subject'].value_counts())\n",
    "print('Electrode counts:')\n",
    "print(full_df['electrode'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edefe191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "\n",
    "FS = 250  # sampling rate in Hz (given by the dataset paper)\n",
    "\n",
    "\n",
    "def bandpass(epoch, low=8, high=90, fs=FS, order=4):\n",
    "    \"\"\"\n",
    "    Band-pass filter: keep only frequencies between `low` and `high` Hz.\n",
    "    epoch: array of shape (n_channels, n_samples)\n",
    "    \"\"\"\n",
    "    nyq = fs / 2\n",
    "    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n",
    "    return filtfilt(b, a, epoch, axis=-1)\n",
    "\n",
    "\n",
    "def notch(epoch, freq=50, fs=FS, q=30):\n",
    "    \"\"\"\n",
    "    Notch filter: remove a narrow band around `freq` Hz (e.g. 50 Hz mains noise).\n",
    "    \"\"\"\n",
    "    nyq = fs / 2\n",
    "    w0 = freq / nyq\n",
    "    b, a = iirnotch(w0, Q=q)\n",
    "    return filtfilt(b, a, epoch, axis=-1)\n",
    "\n",
    "\n",
    "def preprocess_epoch(epoch_raw):\n",
    "    \"\"\"\n",
    "    Full preprocessing for a single trial.\n",
    "    Input:  epoch_raw shape (8, 710)\n",
    "    Output: preprocessed epoch shape (8, 500)\n",
    "    \"\"\"\n",
    "    # Always work in float64 to avoid numerical weirdness\n",
    "    epoch = epoch_raw.astype(np.float64)\n",
    "\n",
    "    # 1) Band-pass 8–90 Hz: keep SSVEP fundamentals + harmonics, remove drifts & ultra-high noise\n",
    "    epoch = bandpass(epoch, low=8, high=90, fs=FS, order=4)\n",
    "\n",
    "    # 2) Notch 50 & 100 Hz: remove mains electrical hum and its first harmonic\n",
    "    epoch = notch(epoch, freq=50, fs=FS, q=30)\n",
    "    epoch = notch(epoch, freq=100, fs=FS, q=30)\n",
    "\n",
    "    # 3) Baseline correction using -0.5s to 0s (first 125 samples at 250 Hz)\n",
    "    baseline = epoch[:, :125].mean(axis=-1, keepdims=True)\n",
    "    epoch = epoch - baseline\n",
    "\n",
    "    # 4) Trim to main SSVEP window.\n",
    "    #    0.5s pre + ~0.14s visual delay => start ~0.64s after trial onset: sample 160\n",
    "    #    2s of stimulation => 500 samples => 160:660\n",
    "    epoch = epoch[:, 160:660]  # shape (8, 500)\n",
    "\n",
    "    # 5) Per-epoch, per-channel z-score:\n",
    "    #    make each channel have mean 0 and std 1 in this epoch, so scales are comparable.\n",
    "    mean = epoch.mean(axis=-1, keepdims=True)\n",
    "    std = epoch.std(axis=-1, keepdims=True) + 1e-8\n",
    "    epoch = (epoch - mean) / std\n",
    "\n",
    "    return epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89dace8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>electrode</th>\n",
       "      <th>block</th>\n",
       "      <th>target</th>\n",
       "      <th>signal</th>\n",
       "      <th>signal_pp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S001</td>\n",
       "      <td>wet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[-52325.52005800724, -53157.22841961553, -554...</td>\n",
       "      <td>[[1.70329534663277, 1.005246832872975, -0.6968...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S001</td>\n",
       "      <td>wet</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-56806.91044371786, -58819.819022406286, -60...</td>\n",
       "      <td>[[2.1173829193890454, 0.23705557026530585, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S001</td>\n",
       "      <td>wet</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[-58424.81901793594, -57290.15513003797, -551...</td>\n",
       "      <td>[[-3.4062449388976734, -0.6271521744047096, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S001</td>\n",
       "      <td>wet</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[-59719.47668310861, -61462.01857698074, -609...</td>\n",
       "      <td>[[0.2641990410447794, -0.39355795229029994, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S001</td>\n",
       "      <td>wet</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>[[-57667.36314698238, -60079.16093344456, -608...</td>\n",
       "      <td>[[0.633041792724005, -0.27745217316847137, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24475</th>\n",
       "      <td>S102</td>\n",
       "      <td>dry</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[[10971.978960751234, 11017.442406263495, 1104...</td>\n",
       "      <td>[[-1.371439566731729, -1.0397680194580703, -2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24476</th>\n",
       "      <td>S102</td>\n",
       "      <td>dry</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>[[11072.293583887433, 11040.330591221487, 1100...</td>\n",
       "      <td>[[0.19956229808600792, 0.5625620121231513, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24477</th>\n",
       "      <td>S102</td>\n",
       "      <td>dry</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>[[11305.064636770763, 11329.919775123582, 1130...</td>\n",
       "      <td>[[-0.25180437619401635, -0.1536912581035672, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>S102</td>\n",
       "      <td>dry</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>[[11089.77264700965, 11050.031247736886, 11049...</td>\n",
       "      <td>[[1.9501752759802595, 1.570491017693854, 1.201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24479</th>\n",
       "      <td>S102</td>\n",
       "      <td>dry</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>[[11370.823465038744, 11417.002166330944, 1141...</td>\n",
       "      <td>[[0.17651830208390856, 0.7252400376681484, 0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24480 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject electrode  block  target  \\\n",
       "0        S001       wet      1       1   \n",
       "1        S001       wet      1       2   \n",
       "2        S001       wet      1       3   \n",
       "3        S001       wet      1       4   \n",
       "4        S001       wet      1       5   \n",
       "...       ...       ...    ...     ...   \n",
       "24475    S102       dry     10       8   \n",
       "24476    S102       dry     10       9   \n",
       "24477    S102       dry     10      10   \n",
       "24478    S102       dry     10      11   \n",
       "24479    S102       dry     10      12   \n",
       "\n",
       "                                                  signal  \\\n",
       "0      [[-52325.52005800724, -53157.22841961553, -554...   \n",
       "1      [[-56806.91044371786, -58819.819022406286, -60...   \n",
       "2      [[-58424.81901793594, -57290.15513003797, -551...   \n",
       "3      [[-59719.47668310861, -61462.01857698074, -609...   \n",
       "4      [[-57667.36314698238, -60079.16093344456, -608...   \n",
       "...                                                  ...   \n",
       "24475  [[10971.978960751234, 11017.442406263495, 1104...   \n",
       "24476  [[11072.293583887433, 11040.330591221487, 1100...   \n",
       "24477  [[11305.064636770763, 11329.919775123582, 1130...   \n",
       "24478  [[11089.77264700965, 11050.031247736886, 11049...   \n",
       "24479  [[11370.823465038744, 11417.002166330944, 1141...   \n",
       "\n",
       "                                               signal_pp  \n",
       "0      [[1.70329534663277, 1.005246832872975, -0.6968...  \n",
       "1      [[2.1173829193890454, 0.23705557026530585, -1....  \n",
       "2      [[-3.4062449388976734, -0.6271521744047096, 3....  \n",
       "3      [[0.2641990410447794, -0.39355795229029994, -0...  \n",
       "4      [[0.633041792724005, -0.27745217316847137, -0....  \n",
       "...                                                  ...  \n",
       "24475  [[-1.371439566731729, -1.0397680194580703, -2....  \n",
       "24476  [[0.19956229808600792, 0.5625620121231513, -1....  \n",
       "24477  [[-0.25180437619401635, -0.1536912581035672, 0...  \n",
       "24478  [[1.9501752759802595, 1.570491017693854, 1.201...  \n",
       "24479  [[0.17651830208390856, 0.7252400376681484, 0.3...  \n",
       "\n",
       "[24480 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['signal_pp'] = full_df['signal'].apply(preprocess_epoch)\n",
    "pp_full_df = full_df\n",
    "pp_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04ea3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (12240, 8, 500)\n",
      "y shape: (12240,) unique targets: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "# Use only dry-electrode trials\n",
    "mask = (pp_full_df['electrode'] == 'dry')\n",
    "df_dry = pp_full_df.loc[mask].reset_index(drop=True)\n",
    "\n",
    "# Stack preprocessed signals into a big 3D array: (n_trials, n_channels, n_samples)\n",
    "X = np.stack(df_dry['signal_pp'].values)   # shape (N_trials, 8, 500)\n",
    "\n",
    "# Targets: 1..12 in the dataset; convert to 0..11 for indexing convenience\n",
    "y = df_dry['target'].values - 1\n",
    "\n",
    "# Keep subject labels for optional per-subject analysis\n",
    "subjects = df_dry['subject'].values\n",
    "\n",
    "print(\"X shape:\", X.shape)   # (N_dry_trials, 8, 500)\n",
    "print(\"y shape:\", y.shape, \"unique targets:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05c7001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FS = 250          # sampling rate (Hz)\n",
    "N_HARMONICS = 5   # number of harmonics to use in references\n",
    "\n",
    "# Target-wise frequency & phase from stimulation_information.pdf -----\n",
    "\n",
    "FREQ_PER_TARGET = np.array([\n",
    "    9.25,   # target 1  → '1'\n",
    "    11.25,  # target 2  → '2'\n",
    "    13.25,  # target 3  → '3'\n",
    "    9.75,   # target 4  → '4'\n",
    "    11.75,  # target 5  → '5'\n",
    "    13.75,  # target 6  → '6'\n",
    "    10.25,  # target 7  → '7'\n",
    "    12.25,  # target 8  → '8'\n",
    "    14.25,  # target 9  → '9'\n",
    "    10.75,  # target 10 → '0'\n",
    "    12.75,  # target 11 → '*'\n",
    "    14.75   # target 12 → '#'\n",
    "], dtype=float)\n",
    "\n",
    "PHASE_PER_TARGET = np.array([\n",
    "    0.0 * np.pi,  # target 1\n",
    "    0.0 * np.pi,  # target 2\n",
    "    0.0 * np.pi,  # target 3\n",
    "    0.5 * np.pi,  # target 4\n",
    "    0.5 * np.pi,  # target 5\n",
    "    0.5 * np.pi,  # target 6\n",
    "    1.0 * np.pi,  # target 7\n",
    "    1.0 * np.pi,  # target 8\n",
    "    1.0 * np.pi,  # target 9\n",
    "    1.5 * np.pi,  # target 10\n",
    "    1.5 * np.pi,  # target 11\n",
    "    1.5 * np.pi   # target 12\n",
    "], dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73fe4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ref_signals_targetwise(freqs, phases, n_samples, fs=FS, n_harmonics=N_HARMONICS):\n",
    "    \"\"\"\n",
    "    Build one reference matrix per target using that target's frequency AND phase.\n",
    "\n",
    "    Returns: list of length n_targets\n",
    "        refs[k] has shape (2 * n_harmonics, n_samples)\n",
    "    \"\"\"\n",
    "    t = np.arange(n_samples) / fs\n",
    "    refs = []\n",
    "\n",
    "    for f, phi in zip(freqs, phases):\n",
    "        components = []\n",
    "        for h in range(1, n_harmonics + 1):\n",
    "            # sin and cos with correct phase offset\n",
    "            components.append(np.sin(2 * np.pi * h * f * t + phi))\n",
    "            components.append(np.cos(2 * np.pi * h * f * t + phi))\n",
    "        Y = np.stack(components, axis=0)  # (2 * n_harmonics, n_samples)\n",
    "        refs.append(Y)\n",
    "\n",
    "    return refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921b66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Filter-bank definition: five contiguous 8 Hz bands from 8–50 Hz\n",
    "FILTER_BANKS = [\n",
    "    (8, 16),\n",
    "    (16, 24),\n",
    "    (24, 32),\n",
    "    (32, 40),\n",
    "    (40, 50),\n",
    "]\n",
    "\n",
    "\n",
    "def cca_on_trial(X_trial, Y_ref, reg=1e-6):\n",
    "    \"\"\"Return the top canonical correlation between one trial and one reference.\"\"\"\n",
    "    # Center each channel/component\n",
    "    Xc = X_trial - X_trial.mean(axis=1, keepdims=True)\n",
    "    Yc = Y_ref - Y_ref.mean(axis=1, keepdims=True)\n",
    "    n = Xc.shape[1]\n",
    "\n",
    "    # Covariance + small ridge for stability\n",
    "    Sxx = (Xc @ Xc.T) / (n - 1) + reg * np.eye(Xc.shape[0])\n",
    "    Syy = (Yc @ Yc.T) / (n - 1) + reg * np.eye(Yc.shape[0])\n",
    "    Sxy = (Xc @ Yc.T) / (n - 1)\n",
    "\n",
    "    # Whitening transforms via eigen decomposition\n",
    "    def inv_sqrt(mat):\n",
    "        vals, vecs = np.linalg.eigh(mat)\n",
    "        vals = np.clip(vals, reg, None)\n",
    "        return vecs @ np.diag(1.0 / np.sqrt(vals)) @ vecs.T\n",
    "\n",
    "    Wx = inv_sqrt(Sxx)\n",
    "    Wy = inv_sqrt(Syy)\n",
    "\n",
    "    # Solve CCA via SVD of the whitened cross-covariance\n",
    "    K = Wx @ Sxy @ Wy\n",
    "    _, s, _ = svd(K, full_matrices=False)\n",
    "    return float(np.clip(s[0], 0.0, 1.0))\n",
    "\n",
    "\n",
    "def fbcca_classify(X_trial, target_refs, filter_bank_params=FILTER_BANKS, fs=FS):\n",
    "    \"\"\"Classify one preprocessed trial using FBCCA and return the predicted target index.\"\"\"\n",
    "    rhos = []\n",
    "    for band_idx, (f_low, f_high) in enumerate(filter_bank_params, start=1):\n",
    "        # Band-specific filtering only (input is already preprocessed)\n",
    "        trial_filt = bandpass(X_trial, low=f_low, high=f_high, fs=fs, order=4)\n",
    "        trial_filt = notch(trial_filt, freq=50, fs=fs, q=30)\n",
    "        trial_filt = notch(trial_filt, freq=100, fs=fs, q=30)\n",
    "\n",
    "        # CCA against each target reference\n",
    "        rho_per_target = [cca_on_trial(trial_filt, ref) for ref in target_refs]\n",
    "        rhos.append(rho_per_target)\n",
    "\n",
    "    rhos = np.asarray(rhos)  # shape (n_bands, n_targets)\n",
    "    weights = np.array([(i ** -1.25) + 0.25 for i in range(1, len(filter_bank_params) + 1)])\n",
    "    scores = (weights[:, None] * (rhos ** 2)).sum(axis=0)\n",
    "    return int(np.argmax(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7508a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference signals for the full window (500 samples)\n",
    "ref_signals = make_ref_signals_targetwise(\n",
    "    FREQ_PER_TARGET,\n",
    "    PHASE_PER_TARGET,\n",
    "    n_samples=500,\n",
    "    fs=FS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94eb2e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train+Val: (9792, 8, 500)\n",
      "Test: (2448, 8, 500)\n"
     ]
    }
   ],
   "source": [
    "# Split into train+val and test sets (80/20 stratified) used by BOTH models\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2025)\n",
    "trainval_idx, test_idx = next(sss.split(X, y))\n",
    "\n",
    "X_trainval, y_trainval = X[trainval_idx], y[trainval_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "print(\"Train+Val:\", X_trainval.shape)\n",
    "print(\"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee5b41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FBCCA test accuracy: 0.7594\n"
     ]
    }
   ],
   "source": [
    "fbcca_test_preds = [fbcca_classify(trial, ref_signals) for trial in X_test]\n",
    "fbcca_test_acc = (np.array(fbcca_test_preds) == y_test).mean()\n",
    "\n",
    "print(f\"FBCCA test accuracy: {fbcca_test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a30f5c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------\n",
    "# Compact EEGNet-like CNN model\n",
    "# -----------------------------\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, n_chans=8, n_samples=500, n_classes=12, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.n_chans = n_chans\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "        self.conv_time = nn.Conv2d(1, 8, kernel_size=(1, 64), padding=(0, 32), bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "\n",
    "        # Depthwise convolution across channels\n",
    "        self.depthwise = nn.Conv2d(8, 16, kernel_size=(n_chans, 1), groups=8, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(1, 4))\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # Separable convolution (depthwise temporal + pointwise)\n",
    "        self.separable = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=(1, 16), padding=(0, 8), groups=16, bias=False),\n",
    "            nn.Conv2d(16, 16, kernel_size=(1, 1), bias=False),\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(1, 8))\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Compute final feature size after convolutions/pooling\n",
    "        dummy = torch.zeros(1, 1, n_chans, n_samples)\n",
    "        with torch.no_grad():\n",
    "            feat = self._forward_features(dummy)\n",
    "        self.classifier = nn.Linear(feat.shape[1], n_classes)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        x = self.conv_time(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        x = self.depthwise(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.separable(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        return x.flatten(start_dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b43051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | val acc 0.5472\n",
      "Epoch 02 | val acc 0.6830\n",
      "Epoch 03 | val acc 0.7289\n",
      "Epoch 04 | val acc 0.7412\n",
      "Epoch 05 | val acc 0.7432\n",
      "Epoch 06 | val acc 0.7611\n",
      "Epoch 07 | val acc 0.7534\n",
      "Epoch 08 | val acc 0.7611\n",
      "Epoch 09 | val acc 0.7703\n",
      "Epoch 10 | val acc 0.7693\n",
      "Epoch 11 | val acc 0.7698\n",
      "Epoch 12 | val acc 0.7754\n",
      "Epoch 13 | val acc 0.7728\n",
      "Epoch 14 | val acc 0.7769\n",
      "Epoch 15 | val acc 0.7739\n",
      "Epoch 16 | val acc 0.7774\n",
      "Epoch 17 | val acc 0.7779\n",
      "Epoch 18 | val acc 0.7759\n",
      "Epoch 19 | val acc 0.7769\n",
      "Epoch 20 | val acc 0.7800\n",
      "Epoch 21 | val acc 0.7800\n",
      "Epoch 22 | val acc 0.7805\n",
      "Epoch 23 | val acc 0.7785\n",
      "Epoch 24 | val acc 0.7820\n",
      "Epoch 25 | val acc 0.7769\n",
      "Epoch 26 | val acc 0.7820\n",
      "Epoch 27 | val acc 0.7876\n",
      "Epoch 28 | val acc 0.7861\n",
      "Epoch 29 | val acc 0.7876\n",
      "Epoch 30 | val acc 0.7846\n",
      "Epoch 31 | val acc 0.7856\n",
      "Epoch 32 | val acc 0.7846\n",
      "Epoch 33 | val acc 0.7887\n",
      "Epoch 34 | val acc 0.7836\n",
      "Epoch 35 | val acc 0.7831\n",
      "Epoch 36 | val acc 0.7841\n",
      "Epoch 37 | val acc 0.7851\n",
      "Epoch 38 | val acc 0.7846\n",
      "Epoch 39 | val acc 0.7851\n",
      "✅ Training complete. Best val acc: 0.7887\n"
     ]
    }
   ],
   "source": [
    "# train_eegnet.py (or one notebook cell)\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# -------------------\n",
    "# Hyperparameters\n",
    "# -------------------\n",
    "EPOCHS = 40\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-3\n",
    "DROPOUT = 0.3\n",
    "PATIENCE = 6\n",
    "CKPT_PATH = \"eegnet_tuned.pth\"\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------\n",
    "# Inner train/val split (ONLY on X_trainval)\n",
    "# -------------------\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2024)\n",
    "train_idx, val_idx = next(sss.split(X_trainval, y_trainval))\n",
    "\n",
    "X_tr = np.expand_dims(X_trainval[train_idx], 1)\n",
    "y_tr = y_trainval[train_idx]\n",
    "X_va = np.expand_dims(X_trainval[val_idx], 1)\n",
    "y_va = y_trainval[val_idx]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.from_numpy(X_tr).float(),\n",
    "                  torch.from_numpy(y_tr).long()),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    TensorDataset(torch.from_numpy(X_va).float(),\n",
    "                  torch.from_numpy(y_va).long()),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# Model + optimiser\n",
    "# -------------------\n",
    "model = EEGNet(\n",
    "    n_chans=8,\n",
    "    n_samples=500,\n",
    "    n_classes=12,\n",
    "    dropout=DROPOUT\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=LR,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# -------------------\n",
    "# Training loop\n",
    "# -------------------\n",
    "best_val = 0.0\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(xb), yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # ---- Validate ----\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            preds = model(xb).argmax(1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.numel()\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch:02d} | val acc {val_acc:.4f}\")\n",
    "\n",
    "    # ---- Early stopping ----\n",
    "    if val_acc > best_val:\n",
    "        best_val = val_acc\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), CKPT_PATH)\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            break\n",
    "\n",
    "print(f\"✅ Training complete. Best val acc: {best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d1683e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Test accuracy: 0.7831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.729     0.779     0.754       204\n",
      "           1      0.779     0.794     0.786       204\n",
      "           2      0.850     0.779     0.813       204\n",
      "           3      0.741     0.770     0.755       204\n",
      "           4      0.731     0.799     0.763       204\n",
      "           5      0.820     0.828     0.824       204\n",
      "           6      0.810     0.838     0.824       204\n",
      "           7      0.805     0.770     0.787       204\n",
      "           8      0.765     0.686     0.724       204\n",
      "           9      0.829     0.833     0.831       204\n",
      "          10      0.816     0.848     0.832       204\n",
      "          11      0.729     0.672     0.699       204\n",
      "\n",
      "    accuracy                          0.783      2448\n",
      "   macro avg      0.784     0.783     0.783      2448\n",
      "weighted avg      0.784     0.783     0.783      2448\n",
      "\n",
      "Confusion matrix:\n",
      " [[159   5   2   8  10   4   4   5   0   4   1   2]\n",
      " [  6 162   2   7   4   6   4   4   2   2   3   2]\n",
      " [  4  11 159   1   4   4   5   5   2   3   4   2]\n",
      " [  9   4   4 157   6   1   3   4   6   3   2   5]\n",
      " [  8   4   1   4 163   3   4   3   6   3   3   2]\n",
      " [  3   3   3   1   5 169   3   3   3   5   2   4]\n",
      " [  6   2   1   3   7   1 171   1   1   2   6   3]\n",
      " [  6   4   3   4  10   2   1 157   3   5   5   4]\n",
      " [  1   8   2   6   7   5   3   4 140   5   3  20]\n",
      " [  1   2   4   5   2   3   4   3   1 170   4   5]\n",
      " [  6   3   4   3   2   0   5   2   3   1 173   2]\n",
      " [  9   0   2  13   3   8   4   4  16   2   6 137]]\n"
     ]
    }
   ],
   "source": [
    "# evaluate_eegnet.py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------\n",
    "# Load trained model\n",
    "# -------------------\n",
    "model = EEGNet(n_chans=8, n_samples=500, n_classes=12)\n",
    "model.load_state_dict(torch.load(\"eegnet_tuned.pth\", map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "# -------------------\n",
    "# Predict on test set\n",
    "# -------------------\n",
    "X_test_t = torch.from_numpy(np.expand_dims(X_test, 1)).float().to(DEVICE)\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_test_t), 64):\n",
    "        logits = model(X_test_t[i:i+64])\n",
    "        preds.append(logits.argmax(1).cpu().numpy())\n",
    "\n",
    "y_pred = np.concatenate(preds)\n",
    "\n",
    "# -------------------\n",
    "# Metrics\n",
    "# -------------------\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"✅ Test accuracy: {acc:.4f}\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e983cff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference.py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = EEGNet(n_chans=8, n_samples=500, n_classes=12)\n",
    "model.load_state_dict(torch.load(\"eegnet_tuned.pth\", map_location=DEVICE))\n",
    "model.to(DEVICE).eval()\n",
    "\n",
    "def predict_epoch(epoch):\n",
    "    \"\"\"\n",
    "    epoch: numpy array (8, 500), preprocessed exactly like training\n",
    "    returns: predicted class index (0..11)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        x = torch.from_numpy(epoch[None, None, ...]).float().to(DEVICE)\n",
    "        return int(model(x).argmax(1).cpu().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50106e7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inkling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
