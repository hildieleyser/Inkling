{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a639a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use stratify argument for train_test_split to maintain class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0829735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f65aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.cloud import storage\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e13f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input, layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6359685",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inkling/lib/python3.10/site-packages/pandas/io/pickle.py:202\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    201\u001b[0m         warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mWarning\u001b[39;00m)\n\u001b[0;32m--> 202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(buffer)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 34\u001b[0m emg_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_emg_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m, in \u001b[0;36mload_emg_dataframe\u001b[0;34m(env_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m blob\u001b[38;5;241m.\u001b[39mdownload_to_file(buffer)\n\u001b[1;32m     31\u001b[0m buffer\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inkling/lib/python3.10/site-packages/pandas/io/pickle.py:207\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;66;03m# e.g.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m--> 207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pc\u001b[38;5;241m.\u001b[39mload(handles\u001b[38;5;241m.\u001b[39mhandle, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inkling/lib/python3.10/site-packages/pandas/compat/pickle_compat.py:231\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fh, encoding, is_verbose)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     up\u001b[38;5;241m.\u001b[39mis_verbose \u001b[38;5;241m=\u001b[39m is_verbose  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(name) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1537\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTACK_GLOBAL requires str\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/inkling/lib/python3.10/site-packages/pandas/compat/pickle_compat.py:162\u001b[0m, in \u001b[0;36mUnpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m    160\u001b[0m key \u001b[38;5;241m=\u001b[39m (module, name)\n\u001b[1;32m    161\u001b[0m module, name \u001b[38;5;241m=\u001b[39m _class_locations_map\u001b[38;5;241m.\u001b[39mget(key, key)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[0;34m(self, module, name)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING:\n\u001b[1;32m   1579\u001b[0m         module \u001b[38;5;241m=\u001b[39m _compat_pickle\u001b[38;5;241m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[0;32m-> 1580\u001b[0m \u001b[38;5;28;43m__import__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproto \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _getattribute(sys\u001b[38;5;241m.\u001b[39mmodules[module], name)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy._core.numeric'"
     ]
    }
   ],
   "source": [
    "def load_environment(env_path: str = \".env\") -> tuple[str, str]:\n",
    "    \"\"\"Load GCP credentials and bucket name from a .env file.\"\"\"\n",
    "    env_file = Path(env_path)\n",
    "    if env_file.is_file():\n",
    "        for line in env_file.read_text().splitlines():\n",
    "            stripped = line.strip()\n",
    "            if not stripped or stripped.startswith(\"#\") or \"=\" not in stripped:\n",
    "                continue\n",
    "            key, value = stripped.split(\"=\", 1)\n",
    "            os.environ.setdefault(key.strip(), value.strip())\n",
    "    credentials_path = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "    bucket_name = os.environ.get(\"GCP_BUCKET_NAME\")\n",
    "    if not credentials_path or not bucket_name:\n",
    "        raise EnvironmentError(\n",
    "            \"GOOGLE_APPLICATION_CREDENTIALS and GCP_BUCKET_NAME must be set in the .env file.\"\n",
    "        )\n",
    "    credentials_file = Path(credentials_path)\n",
    "    if not credentials_file.is_file():\n",
    "        raise FileNotFoundError(f\"Credentials file not found at {credentials_file}\")\n",
    "    # Ensure the env var is exported for the Google client to pick up.\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = str(credentials_file)\n",
    "    return str(credentials_file), bucket_name\n",
    "def load_emg_dataframe(env_path=\".env\"):\n",
    "    _, bucket_name = load_environment(env_path)\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blob_path = \"EMG-nature/Clean_df/emg_trial_level_df.pkl\"\n",
    "    blob = bucket.blob(blob_path)\n",
    "    buffer = BytesIO()\n",
    "    blob.download_to_file(buffer)\n",
    "    buffer.seek(0)\n",
    "    df = pd.read_pickle(buffer)\n",
    "    return df\n",
    "emg_df = load_emg_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8d58ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "signal_fixed\n",
       "(16, 9840)    4800\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_df['signal_fixed'].apply(lambda x: x.shape).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3b01d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant</th>\n",
       "      <th>day</th>\n",
       "      <th>block</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>position</th>\n",
       "      <th>grasp</th>\n",
       "      <th>signal</th>\n",
       "      <th>signal_fixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[3.763498e-05, 1.9842508e-05, 9.071698e-06, 1...</td>\n",
       "      <td>[[3.763498e-05, 1.9842508e-05, 9.071698e-06, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1.0537988e-05, 1.153949e-05, 1.18090165e-05,...</td>\n",
       "      <td>[[1.0537988e-05, 1.153949e-05, 1.18090165e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1.6977565e-05, 1.9937088e-05, 2.1830994e-05,...</td>\n",
       "      <td>[[1.6977565e-05, 1.9937088e-05, 2.1830994e-05,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[3.6807487e-06, 3.2587977e-06, 2.339907e-06, ...</td>\n",
       "      <td>[[3.6807487e-06, 3.2587977e-06, 2.339907e-06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[[1.5383765e-05, 1.8471881e-05, 1.6300444e-05,...</td>\n",
       "      <td>[[1.5383765e-05, 1.8471881e-05, 1.6300444e-05,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant  day  block  trial_id  position  grasp  \\\n",
       "0            1    1      1         1         2      3   \n",
       "1            1    1      1         2         2      3   \n",
       "2            1    1      1         3         2      3   \n",
       "3            1    1      1         4         2      3   \n",
       "4            1    1      1         5         2      3   \n",
       "\n",
       "                                              signal  \\\n",
       "0  [[3.763498e-05, 1.9842508e-05, 9.071698e-06, 1...   \n",
       "1  [[1.0537988e-05, 1.153949e-05, 1.18090165e-05,...   \n",
       "2  [[1.6977565e-05, 1.9937088e-05, 2.1830994e-05,...   \n",
       "3  [[3.6807487e-06, 3.2587977e-06, 2.339907e-06, ...   \n",
       "4  [[1.5383765e-05, 1.8471881e-05, 1.6300444e-05,...   \n",
       "\n",
       "                                        signal_fixed  \n",
       "0  [[3.763498e-05, 1.9842508e-05, 9.071698e-06, 1...  \n",
       "1  [[1.0537988e-05, 1.153949e-05, 1.18090165e-05,...  \n",
       "2  [[1.6977565e-05, 1.9937088e-05, 2.1830994e-05,...  \n",
       "3  [[3.6807487e-06, 3.2587977e-06, 2.339907e-06, ...  \n",
       "4  [[1.5383765e-05, 1.8471881e-05, 1.6300444e-05,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788ce0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9840"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_len = min(sig.shape[1] for sig in emg_df['signal'].values)\n",
    "min_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de691f",
   "metadata": {},
   "source": [
    "Pad or trim every trial to same length\n",
    "\n",
    "This function:\n",
    "\n",
    "trims longer signals\n",
    "\n",
    "zero-pads shorter ones (rare in this dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11dae0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_length(sig, target_len):\n",
    "    current_len = sig.shape[1]\n",
    "    if current_len > target_len:\n",
    "        return sig[:, :target_len]  # trim end\n",
    "    elif current_len < target_len:\n",
    "        pad_width = target_len - current_len\n",
    "        return np.pad(sig, ((0,0),(0,pad_width)), mode='constant')\n",
    "    return sig\n",
    "\n",
    "target_len = min_len\n",
    "\n",
    "emg_df['signal_fixed'] = emg_df['signal'].apply(lambda s: fix_length(s, target_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09de5a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9840"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(sig.shape[1] for sig in emg_df['signal_fixed'].values)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74f00335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emg_df: trial-level df, columns:\n",
    "# ['participant', 'day', 'block', 'trial_id', 'position', 'grasp', 'signal_fixed']\n",
    "\n",
    "# Build X from your fixed-length trial signals\n",
    "X = np.stack(emg_df['signal_fixed'].values)  # shape: (n_trials, 16, T)\n",
    "X = np.expand_dims(X, axis=-1)               # shape: (n_trials, 16, T, 1)\n",
    "\n",
    "REST_GRASP_ID = 6  # adjust if needed\n",
    "y = (emg_df['grasp'].values != REST_GRASP_ID).astype(int)  # 0=rest, 1=active\n",
    "\n",
    "# We'll split using indices so we can map back to emg_df easily\n",
    "indices = np.arange(len(emg_df))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.30,\n",
    "    stratify=emg_df['grasp'].values,  # stratify by 6-grasp labels\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Slice X and y with indices\n",
    "X_train = X[train_idx]\n",
    "X_test  = X[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test  = y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5461a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_dist = emg_df['grasp'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7cda026",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grasps = emg_df['grasp'].values[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52278967",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grasps  = emg_df['grasp'].values[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44b8bed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    560\n",
      "2    560\n",
      "3    560\n",
      "4    560\n",
      "5    560\n",
      "6    560\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(train_grasps).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a92c20d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 16, 9840, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb68f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Infer input shape from X_train\n",
    "# input_shape = X_train.shape[1:]   # (16, T, 1)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(layers.Input(shape=input_shape))\n",
    "\n",
    "# # Conv block 1\n",
    "# model.add(layers.Conv2D(16, (3, 3), padding='same', activation=\"relu\"))\n",
    "# model.add(layers.MaxPool2D(pool_size=(1, 4)))   # pool over time dimension\n",
    "\n",
    "# # Conv block 2\n",
    "# model.add(layers.Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n",
    "# model.add(layers.MaxPool2D(pool_size=(1, 4)))\n",
    "\n",
    "# # Conv block 3 (optional but helps compression)\n",
    "# model.add(layers.Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
    "# model.add(layers.MaxPool2D(pool_size=(1, 4)))\n",
    "\n",
    "# # Flatten + dense\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(1, activation='sigmoid'))   # binary output\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(\n",
    "#     loss='binary_crossentropy',\n",
    "#     optimizer='adam',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# # Simple training (you can add EarlyStopping later)\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=10,           # start small; tune later\n",
    "#     batch_size=16,       # adjust according to GPU/CPU memory\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c398e",
   "metadata": {},
   "source": [
    "having issues with tensorflow, will try the same model with pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d0ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "155645e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emg_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# X from EMG matrices\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[43memg_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal_fixed\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)      \u001b[38;5;66;03m# (n_trials, 16, T)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)                    \u001b[38;5;66;03m# (n_trials, 1, 16, T)  # PyTorch wants channels first\u001b[39;00m\n\u001b[1;32m      5\u001b[0m REST_GRASP_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m  \u001b[38;5;66;03m# adjust if needed\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'emg_df' is not defined"
     ]
    }
   ],
   "source": [
    "# X from EMG matrices\n",
    "X = np.stack(emg_df['signal_fixed'].values)      # (n_trials, 16, T)\n",
    "X = np.expand_dims(X, axis=1)                    # (n_trials, 1, 16, T)  # PyTorch wants channels first\n",
    "\n",
    "REST_GRASP_ID = 6  # adjust if needed\n",
    "grasp_labels = emg_df['grasp'].values\n",
    "y = (grasp_labels != REST_GRASP_ID).astype(int)  # 0 = rest, 1 = active\n",
    "\n",
    "# Split by indices so we can check things later if needed\n",
    "indices = np.arange(len(emg_df))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.30,\n",
    "    stratify=grasp_labels,   # stratify by 6 grasps\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test  = X[test_idx]\n",
    "y_train = y[train_idx]\n",
    "y_test  = y[test_idx]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Train class counts:\", np.bincount(y_train))\n",
    "print(\"Test class counts:\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ca2753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inkling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
